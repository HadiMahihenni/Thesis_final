{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>hyperpartisan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jerry Springer Just Summed Up Trump’s Debate W...</td>\n",
       "      <td>Millions of people tuned in Monday night to wa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Clinton Campaign Charges College Students $500...</td>\n",
       "      <td>The Clintons understand the average American. ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Migrant Reveals Sick Reason He Left…’to F*ck t...</td>\n",
       "      <td>Harassment is known in Arabic as ‘taharrush’. ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trump Said Obama Gave Iran “$150 Billion.” He ...</td>\n",
       "      <td>Democratic President Barack Obama pulled off a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Accused Trump Of Calling Climate Chang...</td>\n",
       "      <td>Democratic nominee Hillary Clinton knows her f...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title  \\\n",
       "0       0  Jerry Springer Just Summed Up Trump’s Debate W...   \n",
       "1       1  Clinton Campaign Charges College Students $500...   \n",
       "2       2  Migrant Reveals Sick Reason He Left…’to F*ck t...   \n",
       "3       3  Trump Said Obama Gave Iran “$150 Billion.” He ...   \n",
       "4       4  Hillary Accused Trump Of Calling Climate Chang...   \n",
       "\n",
       "                                            mainText  hyperpartisan  \n",
       "0  Millions of people tuned in Monday night to wa...           True  \n",
       "1  The Clintons understand the average American. ...           True  \n",
       "2  Harassment is known in Arabic as ‘taharrush’. ...           True  \n",
       "3  Democratic President Barack Obama pulled off a...           True  \n",
       "4  Democratic nominee Hillary Clinton knows her f...           True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Hyperpartisan meta/hyper_news_meta.csv\")\n",
    "#df = pd.read_csv(\"Fake news meta/Fake_news_meta.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new field that concatenates title and text\n",
    "df['title_mainText'] = df['title'] + ' ' + df['mainText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id            0\n",
       "title             0\n",
       "mainText          0\n",
       "hyperpartisan     0\n",
       "title_mainText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2268"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_missing =  df[pd.notnull(df['mainText'])]\n",
    "#df_no_missing =  df[pd.notnull(df['title'])]\n",
    "df_no_missing = df.dropna(subset=['mainText', 'title'])\n",
    "df_no_missing = df_no_missing.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_no_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id           0\n",
       "author         466\n",
       "title            0\n",
       "mainText         0\n",
       "portal           0\n",
       "orientation      0\n",
       "veracity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_missing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing['veracity']=df_no_missing['veracity'].replace(['mixture of true and false','mostly false'], 'false')\n",
    "#df_no_missing['veracity']=df_no_missing['veracity'].replace(['mostly false'], 'false')\n",
    "df_no_missing['veracity']=df_no_missing['veracity'].replace(['mostly true'], 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_no_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_no_missing[df_no_missing.veracity != 'no factual content']\n",
    "#df = df[df.veracity != 'mixture of true and false']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true     1243\n",
       "false     284\n",
       "Name: veracity, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['veracity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new field that concatenates title and text\n",
    "df['title_mainText'] = df['title'] + ' ' + df['mainText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerneral Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = list(string.punctuation)\n",
    "punctuation.append(\"''\")\n",
    "punctuation.append(\"``\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_word_list = stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nlp_pipeline_Alltext(text):\n",
    "    \n",
    "     \n",
    "    \n",
    "    #tokenize words for each sentence\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # without punctuation\n",
    "    text = [token for token in text if token not in punctuation]\n",
    "    \n",
    "    # pos tagger\n",
    "    text = nltk.pos_tag(text)\n",
    "    \n",
    "    # lemmatizer\n",
    "    text = [wordnet_lemmatizer.lemmatize(token.lower(),\"v\") if pos[0] == \"V\" else wordnet_lemmatizer.lemmatize(token.lower()) for token,pos in text]\n",
    "    \n",
    "    # remove punctuation and numbers\n",
    "    text = [token for token in text if token.isalpha()]\n",
    "    \n",
    "    # remove stopwords - be careful with this step    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "    \n",
    "    pre_proc_text =  \" \".join([token for token in text])\n",
    "\n",
    "    return pre_proc_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract only Noun/Verb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = list(string.punctuation)\n",
    "punctuation.append(\"''\")\n",
    "punctuation.append(\"``\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_word_list = stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def nlp_pipeline(text):\n",
    "\n",
    "    \n",
    "    # word tokenizer\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # pos tagger\n",
    "    text = nltk.pos_tag(text)\n",
    "    \n",
    "    #extract nouns\n",
    "    text = [token for token,pos in text if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "    #extract verbs\n",
    "    #text = [token for token,pos in text if (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN' or pos == 'VBP' or pos == 'VBZ')]\n",
    "    \n",
    "    # without punctuation\n",
    "    text = [token for token in text if token not in punctuation]\n",
    "    \n",
    "    # remove punctuation and numbers\n",
    "    text = [token for token in text if token.isalpha()]\n",
    "    \n",
    "    # remove stopwords - be careful with this step    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "    \n",
    "    # lemmatizer for nouns\n",
    "    text = [wordnet_lemmatizer.lemmatize(token.lower()) for token in text]\n",
    "        \n",
    "    # lemmatizer for verbs\n",
    "    #text = [wordnet_lemmatizer.lemmatize(token.lower(),\"v\") for token in text]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_preprocessed'] = df['title'].apply(nlp_pipeline_Alltext)\n",
    "df['mainText_preprocessed'] = df['mainText'].apply(nlp_pipeline_Alltext)\n",
    "df['title_mainText_preprocessed'] = df['title_mainText'].apply(nlp_pipeline_Alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mainText_verbs'] = df['mainText'].apply(nlp_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mainText_nouns'] = df['mainText'].apply(nlp_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>title_mainText</th>\n",
       "      <th>title_preprocessed</th>\n",
       "      <th>mainText_preprocessed</th>\n",
       "      <th>title_mainText_preprocessed</th>\n",
       "      <th>mainText_verbs</th>\n",
       "      <th>mainText_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jerry Springer Just Summed Up Trump’s Debate W...</td>\n",
       "      <td>Millions of people tuned in Monday night to wa...</td>\n",
       "      <td>True</td>\n",
       "      <td>Jerry Springer Just Summed Up Trump’s Debate W...</td>\n",
       "      <td>jerry springer summed trump debate perfect tweet</td>\n",
       "      <td>million people tune monday night watch coverag...</td>\n",
       "      <td>jerry springer summed trump debate perfect twe...</td>\n",
       "      <td>[tune, watch, go, come, report, broadcast, fol...</td>\n",
       "      <td>[million, people, monday, night, coverage, deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Clinton Campaign Charges College Students $500...</td>\n",
       "      <td>The Clintons understand the average American. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Clinton Campaign Charges College Students $500...</td>\n",
       "      <td>clinton campaign charge college students atten...</td>\n",
       "      <td>clinton understand average american know like ...</td>\n",
       "      <td>clinton campaign charge college students atten...</td>\n",
       "      <td>[understand, know, make, suffer, lie, get, pay...</td>\n",
       "      <td>[clinton, broke, hillary, clinton, woman, peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Migrant Reveals Sick Reason He Left…’to F*ck t...</td>\n",
       "      <td>Harassment is known in Arabic as ‘taharrush’. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Migrant Reveals Sick Reason He Left…’to F*ck t...</td>\n",
       "      <td>migrant reveals sick reason woman</td>\n",
       "      <td>harassment know arabic taharrush mass sexual a...</td>\n",
       "      <td>migrant reveals sick reason woman harassment k...</td>\n",
       "      <td>[know, document, begin, call, hide, feel, leav...</td>\n",
       "      <td>[harassment, arabic, taharrush, mass, assault,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trump Said Obama Gave Iran “$150 Billion.” He ...</td>\n",
       "      <td>Democratic President Barack Obama pulled off a...</td>\n",
       "      <td>True</td>\n",
       "      <td>Trump Said Obama Gave Iran “$150 Billion.” He ...</td>\n",
       "      <td>trump said obama gave iran give nothing</td>\n",
       "      <td>democratic president barack obama pull histori...</td>\n",
       "      <td>trump said obama gave iran give nothing democr...</td>\n",
       "      <td>[pull, engineer, freeze, lift, strangle, engin...</td>\n",
       "      <td>[president, barack, obama, coup, accord, iran,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Accused Trump Of Calling Climate Chang...</td>\n",
       "      <td>Democratic nominee Hillary Clinton knows her f...</td>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Accused Trump Of Calling Climate Chang...</td>\n",
       "      <td>hillary accuse trump calling climate change ch...</td>\n",
       "      <td>democratic nominee hillary clinton know fact t...</td>\n",
       "      <td>hillary accuse trump calling climate change ch...</td>\n",
       "      <td>[know, bust, call, rely, slam, rat, call, repe...</td>\n",
       "      <td>[nominee, hillary, clinton, fact, debate, trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title  \\\n",
       "0       0  Jerry Springer Just Summed Up Trump’s Debate W...   \n",
       "1       1  Clinton Campaign Charges College Students $500...   \n",
       "2       2  Migrant Reveals Sick Reason He Left…’to F*ck t...   \n",
       "3       3  Trump Said Obama Gave Iran “$150 Billion.” He ...   \n",
       "4       4  Hillary Accused Trump Of Calling Climate Chang...   \n",
       "\n",
       "                                            mainText  hyperpartisan  \\\n",
       "0  Millions of people tuned in Monday night to wa...           True   \n",
       "1  The Clintons understand the average American. ...           True   \n",
       "2  Harassment is known in Arabic as ‘taharrush’. ...           True   \n",
       "3  Democratic President Barack Obama pulled off a...           True   \n",
       "4  Democratic nominee Hillary Clinton knows her f...           True   \n",
       "\n",
       "                                      title_mainText  \\\n",
       "0  Jerry Springer Just Summed Up Trump’s Debate W...   \n",
       "1  Clinton Campaign Charges College Students $500...   \n",
       "2  Migrant Reveals Sick Reason He Left…’to F*ck t...   \n",
       "3  Trump Said Obama Gave Iran “$150 Billion.” He ...   \n",
       "4  Hillary Accused Trump Of Calling Climate Chang...   \n",
       "\n",
       "                                  title_preprocessed  \\\n",
       "0   jerry springer summed trump debate perfect tweet   \n",
       "1  clinton campaign charge college students atten...   \n",
       "2                  migrant reveals sick reason woman   \n",
       "3            trump said obama gave iran give nothing   \n",
       "4  hillary accuse trump calling climate change ch...   \n",
       "\n",
       "                               mainText_preprocessed  \\\n",
       "0  million people tune monday night watch coverag...   \n",
       "1  clinton understand average american know like ...   \n",
       "2  harassment know arabic taharrush mass sexual a...   \n",
       "3  democratic president barack obama pull histori...   \n",
       "4  democratic nominee hillary clinton know fact t...   \n",
       "\n",
       "                         title_mainText_preprocessed  \\\n",
       "0  jerry springer summed trump debate perfect twe...   \n",
       "1  clinton campaign charge college students atten...   \n",
       "2  migrant reveals sick reason woman harassment k...   \n",
       "3  trump said obama gave iran give nothing democr...   \n",
       "4  hillary accuse trump calling climate change ch...   \n",
       "\n",
       "                                      mainText_verbs  \\\n",
       "0  [tune, watch, go, come, report, broadcast, fol...   \n",
       "1  [understand, know, make, suffer, lie, get, pay...   \n",
       "2  [know, document, begin, call, hide, feel, leav...   \n",
       "3  [pull, engineer, freeze, lift, strangle, engin...   \n",
       "4  [know, bust, call, rely, slam, rat, call, repe...   \n",
       "\n",
       "                                      mainText_nouns  \n",
       "0  [million, people, monday, night, coverage, deb...  \n",
       "1  [clinton, broke, hillary, clinton, woman, peop...  \n",
       "2  [harassment, arabic, taharrush, mass, assault,...  \n",
       "3  [president, barack, obama, coup, accord, iran,...  \n",
       "4  [nominee, hillary, clinton, fact, debate, trum...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2234"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unnecessary columns\n",
    "df = df[['doc_id','title', 'mainText', 'orientation', 'veracity', 'title_mainText', 'title_preprocessed', \n",
    "        'mainText_preprocessed','title_mainText_preprocessed','mainText_nouns','mainText_verbs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"hyper_preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day after explosive devices were discovered in the Manhattan neighborhood of Chelsea and in Seaside Park and Elizabeth in New Jersey, Republican nominee Donald Trump repeated his calls to implement police profiling to stop more attacks in the United States. \"Our local police, they know who a lot of these people are. They are afraid to do anything about it because they don't want to be accused of profiling and they don't want to be accused of all sorts of things,\" Trump said on \"Fox and Friends\" when asked what policies he would implement as president to \"get tough\" on terrorism. He argued that the country had no other choice but to follow the lead of Israel. \"Israel has done an unbelievable job, and they will profile. They profile. They see somebody that's suspicious,\" he said, \"they will profile. They will take that person in and check out. Do we have a choice? Look what's going on. Do we really have a choice? We're trying to be so politically correct in our country, and this is only going to get worse.\" Trump previously made similar comments. After the Orlando nightclub shooting in June, he said in an interview on \"Face the Nation\" that it was something the U.S. needed to seriously consider.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('BuzzFeed-Webis/0002.xml')\n",
    "root = tree.getroot()\n",
    "article = root.find(\"mainText\").text\n",
    "print (article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Our local police, they know who a lot of these people are.\n"
     ]
    }
   ],
   "source": [
    "# split into sentences\n",
    "sentences = nltk.sent_tokenize(article) \n",
    "\n",
    "# take one single sentence \n",
    "\n",
    "sentence = sentences[1]\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'day', 'after', 'explosive', 'devices', 'were', 'discovered', 'in', 'the', 'Manhattan', 'neighborhood', 'of', 'Chelsea', 'and', 'in', 'Seaside', 'Park', 'and', 'Elizabeth', 'in', 'New', 'Jersey', ',', 'Republican', 'nominee', 'Donald', 'Trump', 'repeated', 'his', 'calls', 'to', 'implement', 'police', 'profiling', 'to', 'stop', 'more', 'attacks', 'in', 'the', 'United', 'States', '.', '``', 'Our', 'local', 'police', ',', 'they', 'know', 'who', 'a', 'lot', 'of', 'these', 'people', 'are', '.', 'They', 'are', 'afraid', 'to', 'do', 'anything', 'about', 'it', 'because', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accused', 'of', 'profiling', 'and', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accused', 'of', 'all', 'sorts', 'of', 'things', ',', \"''\", 'Trump', 'said', 'on', '``', 'Fox', 'and', 'Friends', \"''\", 'when', 'asked', 'what', 'policies', 'he', 'would', 'implement', 'as', 'president', 'to', '``', 'get', 'tough', \"''\", 'on', 'terrorism', '.', 'He', 'argued', 'that', 'the', 'country', 'had', 'no', 'other', 'choice', 'but', 'to', 'follow', 'the', 'lead', 'of', 'Israel', '.', '``', 'Israel', 'has', 'done', 'an', 'unbelievable', 'job', ',', 'and', 'they', 'will', 'profile', '.', 'They', 'profile', '.', 'They', 'see', 'somebody', 'that', \"'s\", 'suspicious', ',', \"''\", 'he', 'said', ',', '``', 'they', 'will', 'profile', '.', 'They', 'will', 'take', 'that', 'person', 'in', 'and', 'check', 'out', '.', 'Do', 'we', 'have', 'a', 'choice', '?', 'Look', 'what', \"'s\", 'going', 'on', '.', 'Do', 'we', 'really', 'have', 'a', 'choice', '?', 'We', \"'re\", 'trying', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', ',', 'and', 'this', 'is', 'only', 'going', 'to', 'get', 'worse', '.', \"''\", 'Trump', 'previously', 'made', 'similar', 'comments', '.', 'After', 'the', 'Orlando', 'nightclub', 'shooting', 'in', 'June', ',', 'he', 'said', 'in', 'an', 'interview', 'on', '``', 'Face', 'the', 'Nation', \"''\", 'that', 'it', 'was', 'something', 'the', 'U.S.', 'needed', 'to', 'seriously', 'consider', '.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenizer\n",
    "tokenized_sentence = nltk.word_tokenize(article)\n",
    "print (tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('One', 'CD'), ('day', 'NN'), ('after', 'IN'), ('explosive', 'JJ'), ('devices', 'NNS'), ('were', 'VBD'), ('discovered', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('Manhattan', 'NNP'), ('neighborhood', 'NN'), ('of', 'IN'), ('Chelsea', 'NNP'), ('and', 'CC'), ('in', 'IN'), ('Seaside', 'NNP'), ('Park', 'NNP'), ('and', 'CC'), ('Elizabeth', 'NNP'), ('in', 'IN'), ('New', 'NNP'), ('Jersey', 'NNP'), (',', ','), ('Republican', 'NNP'), ('nominee', 'NN'), ('Donald', 'NNP'), ('Trump', 'NNP'), ('repeated', 'VBD'), ('his', 'PRP$'), ('calls', 'NNS'), ('to', 'TO'), ('implement', 'VB'), ('police', 'NN'), ('profiling', 'VBG'), ('to', 'TO'), ('stop', 'VB'), ('more', 'JJR'), ('attacks', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.'), ('``', '``'), ('Our', 'PRP$'), ('local', 'JJ'), ('police', 'NN'), (',', ','), ('they', 'PRP'), ('know', 'VBP'), ('who', 'WP'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('these', 'DT'), ('people', 'NNS'), ('are', 'VBP'), ('.', '.'), ('They', 'PRP'), ('are', 'VBP'), ('afraid', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('anything', 'NN'), ('about', 'IN'), ('it', 'PRP'), ('because', 'IN'), ('they', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('to', 'TO'), ('be', 'VB'), ('accused', 'VBN'), ('of', 'IN'), ('profiling', 'VBG'), ('and', 'CC'), ('they', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('want', 'VB'), ('to', 'TO'), ('be', 'VB'), ('accused', 'VBN'), ('of', 'IN'), ('all', 'DT'), ('sorts', 'NNS'), ('of', 'IN'), ('things', 'NNS'), (',', ','), (\"''\", \"''\"), ('Trump', 'NNP'), ('said', 'VBD'), ('on', 'IN'), ('``', '``'), ('Fox', 'NNP'), ('and', 'CC'), ('Friends', 'NNPS'), (\"''\", \"''\"), ('when', 'WRB'), ('asked', 'VBD'), ('what', 'WP'), ('policies', 'NNS'), ('he', 'PRP'), ('would', 'MD'), ('implement', 'VB'), ('as', 'IN'), ('president', 'NN'), ('to', 'TO'), ('``', '``'), ('get', 'VB'), ('tough', 'JJ'), (\"''\", \"''\"), ('on', 'IN'), ('terrorism', 'NN'), ('.', '.'), ('He', 'PRP'), ('argued', 'VBD'), ('that', 'IN'), ('the', 'DT'), ('country', 'NN'), ('had', 'VBD'), ('no', 'DT'), ('other', 'JJ'), ('choice', 'NN'), ('but', 'CC'), ('to', 'TO'), ('follow', 'VB'), ('the', 'DT'), ('lead', 'NN'), ('of', 'IN'), ('Israel', 'NNP'), ('.', '.'), ('``', '``'), ('Israel', 'NNP'), ('has', 'VBZ'), ('done', 'VBN'), ('an', 'DT'), ('unbelievable', 'JJ'), ('job', 'NN'), (',', ','), ('and', 'CC'), ('they', 'PRP'), ('will', 'MD'), ('profile', 'VB'), ('.', '.'), ('They', 'PRP'), ('profile', 'VBP'), ('.', '.'), ('They', 'PRP'), ('see', 'VBP'), ('somebody', 'NN'), ('that', 'WDT'), (\"'s\", 'VBZ'), ('suspicious', 'JJ'), (',', ','), (\"''\", \"''\"), ('he', 'PRP'), ('said', 'VBD'), (',', ','), ('``', '``'), ('they', 'PRP'), ('will', 'MD'), ('profile', 'VB'), ('.', '.'), ('They', 'PRP'), ('will', 'MD'), ('take', 'VB'), ('that', 'DT'), ('person', 'NN'), ('in', 'IN'), ('and', 'CC'), ('check', 'VB'), ('out', 'RP'), ('.', '.'), ('Do', 'VBP'), ('we', 'PRP'), ('have', 'VB'), ('a', 'DT'), ('choice', 'NN'), ('?', '.'), ('Look', 'VB'), ('what', 'WP'), (\"'s\", 'VBZ'), ('going', 'VBG'), ('on', 'IN'), ('.', '.'), ('Do', 'VBP'), ('we', 'PRP'), ('really', 'RB'), ('have', 'VBP'), ('a', 'DT'), ('choice', 'NN'), ('?', '.'), ('We', 'PRP'), (\"'re\", 'VBP'), ('trying', 'VBG'), ('to', 'TO'), ('be', 'VB'), ('so', 'RB'), ('politically', 'RB'), ('correct', 'JJ'), ('in', 'IN'), ('our', 'PRP$'), ('country', 'NN'), (',', ','), ('and', 'CC'), ('this', 'DT'), ('is', 'VBZ'), ('only', 'RB'), ('going', 'VBG'), ('to', 'TO'), ('get', 'VB'), ('worse', 'JJR'), ('.', '.'), (\"''\", \"''\"), ('Trump', 'NNP'), ('previously', 'RB'), ('made', 'VBD'), ('similar', 'JJ'), ('comments', 'NNS'), ('.', '.'), ('After', 'IN'), ('the', 'DT'), ('Orlando', 'NNP'), ('nightclub', 'NN'), ('shooting', 'VBG'), ('in', 'IN'), ('June', 'NNP'), (',', ','), ('he', 'PRP'), ('said', 'VBD'), ('in', 'IN'), ('an', 'DT'), ('interview', 'NN'), ('on', 'IN'), ('``', '``'), ('Face', 'NNP'), ('the', 'DT'), ('Nation', 'NNP'), (\"''\", \"''\"), ('that', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('something', 'NN'), ('the', 'DT'), ('U.S.', 'NNP'), ('needed', 'VBD'), ('to', 'TO'), ('seriously', 'RB'), ('consider', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "# you use the pos-tagger (it gives you back a list of tuples (word,pos))\n",
    "pos_sentence = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "print (pos_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text = [wordnet_lemmatizer.lemmatize(token.lower(),\"v\") if pos[0] == \"V\" else wordnet_lemmatizer.lemmatize(token.lower()) for token,pos in pos_sentence ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', \"''\", '``']\n",
      "['one', 'day', 'after', 'explosive', 'device', 'be', 'discover', 'in', 'the', 'manhattan', 'neighborhood', 'of', 'chelsea', 'and', 'in', 'seaside', 'park', 'and', 'elizabeth', 'in', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeat', 'his', 'call', 'to', 'implement', 'police', 'profile', 'to', 'stop', 'more', 'attack', 'in', 'the', 'united', 'state', 'our', 'local', 'police', 'they', 'know', 'who', 'a', 'lot', 'of', 'these', 'people', 'be', 'they', 'be', 'afraid', 'to', 'do', 'anything', 'about', 'it', 'because', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accuse', 'of', 'profile', 'and', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accuse', 'of', 'all', 'sort', 'of', 'thing', 'trump', 'say', 'on', 'fox', 'and', 'friend', 'when', 'ask', 'what', 'policy', 'he', 'would', 'implement', 'a', 'president', 'to', 'get', 'tough', 'on', 'terrorism', 'he', 'argue', 'that', 'the', 'country', 'have', 'no', 'other', 'choice', 'but', 'to', 'follow', 'the', 'lead', 'of', 'israel', 'israel', 'have', 'do', 'an', 'unbelievable', 'job', 'and', 'they', 'will', 'profile', 'they', 'profile', 'they', 'see', 'somebody', 'that', \"'s\", 'suspicious', 'he', 'say', 'they', 'will', 'profile', 'they', 'will', 'take', 'that', 'person', 'in', 'and', 'check', 'out', 'do', 'we', 'have', 'a', 'choice', 'look', 'what', \"'s\", 'go', 'on', 'do', 'we', 'really', 'have', 'a', 'choice', 'we', \"'re\", 'try', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', 'and', 'this', 'be', 'only', 'go', 'to', 'get', 'worse', 'trump', 'previously', 'make', 'similar', 'comment', 'after', 'the', 'orlando', 'nightclub', 'shoot', 'in', 'june', 'he', 'say', 'in', 'an', 'interview', 'on', 'face', 'the', 'nation', 'that', 'it', 'be', 'something', 'the', 'u.s.', 'need', 'to', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "# without punctuation\n",
    "import string\n",
    "\n",
    "# defining punctuation to be removed\n",
    "punctuation = list(string.punctuation)\n",
    "punctuation.append(\"''\")\n",
    "punctuation.append(\"``\")\n",
    "print (punctuation)\n",
    "\n",
    "#Remove punctuation\n",
    "without_punct_sentence = [token for token in text if token not in punctuation]\n",
    "print (without_punct_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'after', 'explosive', 'device', 'be', 'discover', 'in', 'the', 'manhattan', 'neighborhood', 'of', 'chelsea', 'and', 'in', 'seaside', 'park', 'and', 'elizabeth', 'in', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeat', 'his', 'call', 'to', 'implement', 'police', 'profile', 'to', 'stop', 'more', 'attack', 'in', 'the', 'united', 'state', 'our', 'local', 'police', 'they', 'know', 'who', 'a', 'lot', 'of', 'these', 'people', 'be', 'they', 'be', 'afraid', 'to', 'do', 'anything', 'about', 'it', 'because', 'they', 'do', 'want', 'to', 'be', 'accuse', 'of', 'profile', 'and', 'they', 'do', 'want', 'to', 'be', 'accuse', 'of', 'all', 'sort', 'of', 'thing', 'trump', 'say', 'on', 'fox', 'and', 'friend', 'when', 'ask', 'what', 'policy', 'he', 'would', 'implement', 'a', 'president', 'to', 'get', 'tough', 'on', 'terrorism', 'he', 'argue', 'that', 'the', 'country', 'have', 'no', 'other', 'choice', 'but', 'to', 'follow', 'the', 'lead', 'of', 'israel', 'israel', 'have', 'do', 'an', 'unbelievable', 'job', 'and', 'they', 'will', 'profile', 'they', 'profile', 'they', 'see', 'somebody', 'that', 'suspicious', 'he', 'say', 'they', 'will', 'profile', 'they', 'will', 'take', 'that', 'person', 'in', 'and', 'check', 'out', 'do', 'we', 'have', 'a', 'choice', 'look', 'what', 'go', 'on', 'do', 'we', 'really', 'have', 'a', 'choice', 'we', 'try', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', 'and', 'this', 'be', 'only', 'go', 'to', 'get', 'worse', 'trump', 'previously', 'make', 'similar', 'comment', 'after', 'the', 'orlando', 'nightclub', 'shoot', 'in', 'june', 'he', 'say', 'in', 'an', 'interview', 'on', 'face', 'the', 'nation', 'that', 'it', 'be', 'something', 'the', 'need', 'to', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "text = [token for token in without_punct_sentence if token.isalpha()]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'explosive', 'device', 'discover', 'manhattan', 'neighborhood', 'chelsea', 'seaside', 'park', 'elizabeth', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeat', 'call', 'implement', 'police', 'profile', 'stop', 'attack', 'united', 'state', 'local', 'police', 'know', 'lot', 'people', 'afraid', 'anything', 'want', 'accuse', 'profile', 'want', 'accuse', 'sort', 'thing', 'trump', 'say', 'fox', 'friend', 'ask', 'policy', 'would', 'implement', 'president', 'get', 'tough', 'terrorism', 'argue', 'country', 'choice', 'follow', 'lead', 'israel', 'israel', 'unbelievable', 'job', 'profile', 'profile', 'see', 'somebody', 'suspicious', 'say', 'profile', 'take', 'person', 'check', 'choice', 'look', 'go', 'really', 'choice', 'try', 'politically', 'correct', 'country', 'go', 'get', 'worse', 'trump', 'previously', 'make', 'similar', 'comment', 'orlando', 'nightclub', 'shoot', 'june', 'say', 'interview', 'face', 'nation', 'something', 'need', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_word_list = stopwords.words('english')\n",
    "#print (stop_word_list)\n",
    "\n",
    "# removing stopwords\n",
    "without_stopwords_sentence = [word for word in text if word not in stop_word_list]\n",
    "print (without_stopwords_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'after', 'explosive', 'devices', 'were', 'discovered', 'in', 'the', 'manhattan', 'neighborhood', 'of', 'chelsea', 'and', 'in', 'seaside', 'park', 'and', 'elizabeth', 'in', 'new', 'jersey', ',', 'republican', 'nominee', 'donald', 'trump', 'repeated', 'his', 'calls', 'to', 'implement', 'police', 'profiling', 'to', 'stop', 'more', 'attacks', 'in', 'the', 'united', 'states', '.', '``', 'our', 'local', 'police', ',', 'they', 'know', 'who', 'a', 'lot', 'of', 'these', 'people', 'are', '.', 'they', 'are', 'afraid', 'to', 'do', 'anything', 'about', 'it', 'because', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accused', 'of', 'profiling', 'and', 'they', 'do', \"n't\", 'want', 'to', 'be', 'accused', 'of', 'all', 'sorts', 'of', 'things', ',', \"''\", 'trump', 'said', 'on', '``', 'fox', 'and', 'friends', \"''\", 'when', 'asked', 'what', 'policies', 'he', 'would', 'implement', 'as', 'president', 'to', '``', 'get', 'tough', \"''\", 'on', 'terrorism', '.', 'he', 'argued', 'that', 'the', 'country', 'had', 'no', 'other', 'choice', 'but', 'to', 'follow', 'the', 'lead', 'of', 'israel', '.', '``', 'israel', 'has', 'done', 'an', 'unbelievable', 'job', ',', 'and', 'they', 'will', 'profile', '.', 'they', 'profile', '.', 'they', 'see', 'somebody', 'that', \"'s\", 'suspicious', ',', \"''\", 'he', 'said', ',', '``', 'they', 'will', 'profile', '.', 'they', 'will', 'take', 'that', 'person', 'in', 'and', 'check', 'out', '.', 'do', 'we', 'have', 'a', 'choice', '?', 'look', 'what', \"'s\", 'going', 'on', '.', 'do', 'we', 'really', 'have', 'a', 'choice', '?', 'we', \"'re\", 'trying', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', ',', 'and', 'this', 'is', 'only', 'going', 'to', 'get', 'worse', '.', \"''\", 'trump', 'previously', 'made', 'similar', 'comments', '.', 'after', 'the', 'orlando', 'nightclub', 'shooting', 'in', 'june', ',', 'he', 'said', 'in', 'an', 'interview', 'on', '``', 'face', 'the', 'nation', \"''\", 'that', 'it', 'was', 'something', 'the', 'u.s.', 'needed', 'to', 'seriously', 'consider', '.']\n"
     ]
    }
   ],
   "source": [
    "# lowering words\n",
    "lowercased_sentence = [word.lower() for word in tokenized_sentence]\n",
    "print (lowercased_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', \"''\", '``']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lowercased_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7fe5b8e7f588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Remove punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mwithout_punct_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlowercased_sentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwithout_punct_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lowercased_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "# without punctuation\n",
    "import string\n",
    "\n",
    "# defining punctuation to be removed\n",
    "punctuation = list(string.punctuation)\n",
    "punctuation.append(\"''\")\n",
    "punctuation.append(\"``\")\n",
    "print (punctuation)\n",
    "\n",
    "#Remove punctuation\n",
    "without_punct_sentence = [token for token in lowercased_sentence if token not in punctuation]\n",
    "print (without_punct_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'explosive', 'devices', 'discovered', 'manhattan', 'neighborhood', 'chelsea', 'seaside', 'park', 'elizabeth', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeated', 'calls', 'implement', 'police', 'profiling', 'stop', 'attacks', 'united', 'states', 'local', 'police', 'know', 'lot', 'people', 'afraid', 'anything', \"n't\", 'want', 'accused', 'profiling', \"n't\", 'want', 'accused', 'sorts', 'things', 'trump', 'said', 'fox', 'friends', 'asked', 'policies', 'would', 'implement', 'president', 'get', 'tough', 'terrorism', 'argued', 'country', 'choice', 'follow', 'lead', 'israel', 'israel', 'done', 'unbelievable', 'job', 'profile', 'profile', 'see', 'somebody', \"'s\", 'suspicious', 'said', 'profile', 'take', 'person', 'check', 'choice', 'look', \"'s\", 'going', 'really', 'choice', \"'re\", 'trying', 'politically', 'correct', 'country', 'going', 'get', 'worse', 'trump', 'previously', 'made', 'similar', 'comments', 'orlando', 'nightclub', 'shooting', 'june', 'said', 'interview', 'face', 'nation', 'something', 'u.s.', 'needed', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_word_list = stopwords.words('english')\n",
    "#print (stop_word_list)\n",
    "\n",
    "# removing stopwords\n",
    "without_stopwords_sentence = [word for word in without_punct_sentence if word not in stop_word_list]\n",
    "print (without_stopwords_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'explosive', 'devices', 'discovered', 'manhattan', 'neighborhood', 'chelsea', 'seaside', 'park', 'elizabeth', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeated', 'calls', 'implement', 'police', 'profiling', 'stop', 'attacks', 'united', 'states', 'local', 'police', 'know', 'lot', 'people', 'afraid', 'anything', 'want', 'accused', 'profiling', 'want', 'accused', 'sorts', 'things', 'trump', 'said', 'fox', 'friends', 'asked', 'policies', 'would', 'implement', 'president', 'get', 'tough', 'terrorism', 'argued', 'country', 'choice', 'follow', 'lead', 'israel', 'israel', 'done', 'unbelievable', 'job', 'profile', 'profile', 'see', 'somebody', 'suspicious', 'said', 'profile', 'take', 'person', 'check', 'choice', 'look', 'going', 'really', 'choice', 'trying', 'politically', 'correct', 'country', 'going', 'get', 'worse', 'trump', 'previously', 'made', 'similar', 'comments', 'orlando', 'nightclub', 'shooting', 'june', 'said', 'interview', 'face', 'nation', 'something', 'needed', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "# keeping words (alpha is a \"word\" not a number)\n",
    "\n",
    "only_words_sentence = [word for word in without_stopwords_sentence if word.isalpha()]\n",
    "print (only_words_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'explos', 'devic', 'discov', 'manhattan', 'neighborhood', 'chelsea', 'seasid', 'park', 'elizabeth', 'new', 'jersey', 'republican', 'nomine', 'donald', 'trump', 'repeat', 'call', 'implement', 'polic', 'profil', 'stop', 'attack', 'unit', 'state', 'local', 'polic', 'know', 'lot', 'peopl', 'afraid', 'anyth', 'want', 'accus', 'profil', 'want', 'accus', 'sort', 'thing', 'trump', 'said', 'fox', 'friend', 'ask', 'polici', 'would', 'implement', 'presid', 'get', 'tough', 'terror', 'argu', 'countri', 'choic', 'follow', 'lead', 'israel', 'israel', 'done', 'unbeliev', 'job', 'profil', 'profil', 'see', 'somebodi', 'suspici', 'said', 'profil', 'take', 'person', 'check', 'choic', 'look', 'go', 'realli', 'choic', 'tri', 'polit', 'correct', 'countri', 'go', 'get', 'wors', 'trump', 'previous', 'made', 'similar', 'comment', 'orlando', 'nightclub', 'shoot', 'june', 'said', 'interview', 'face', 'nation', 'someth', 'need', 'serious', 'consid']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "# import the library\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "stem_sentence = [snowball_stemmer.stem(word) for word in only_words_sentence]\n",
    "print (stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'explosive', 'device', 'discovered', 'manhattan', 'neighborhood', 'chelsea', 'seaside', 'park', 'elizabeth', 'new', 'jersey', 'republican', 'nominee', 'donald', 'trump', 'repeated', 'call', 'implement', 'police', 'profiling', 'stop', 'attack', 'united', 'state', 'local', 'police', 'know', 'lot', 'people', 'afraid', 'anything', 'want', 'accused', 'profiling', 'want', 'accused', 'sort', 'thing', 'trump', 'said', 'fox', 'friend', 'asked', 'policy', 'would', 'implement', 'president', 'get', 'tough', 'terrorism', 'argued', 'country', 'choice', 'follow', 'lead', 'israel', 'israel', 'done', 'unbelievable', 'job', 'profile', 'profile', 'see', 'somebody', 'suspicious', 'said', 'profile', 'take', 'person', 'check', 'choice', 'look', 'going', 'really', 'choice', 'trying', 'politically', 'correct', 'country', 'going', 'get', 'worse', 'trump', 'previously', 'made', 'similar', 'comment', 'orlando', 'nightclub', 'shooting', 'june', 'said', 'interview', 'face', 'nation', 'something', 'needed', 'seriously', 'consider']\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemma_sent = [wordnet_lemmatizer.lemmatize(word) for word in only_words_sentence]\n",
    "print (lemma_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'CD'), ('day', 'NN'), ('explosive', 'JJ'), ('device', 'NN'), ('discovered', 'VBD'), ('manhattan', 'JJ'), ('neighborhood', 'NN'), ('chelsea', 'NN'), ('seaside', 'NN'), ('park', 'NN'), ('elizabeth', 'VBZ'), ('new', 'JJ'), ('jersey', 'JJ'), ('republican', 'JJ'), ('nominee', 'NN'), ('donald', 'NN'), ('trump', 'NN'), ('repeated', 'VBD'), ('call', 'JJ'), ('implement', 'JJ'), ('police', 'NN'), ('profiling', 'VBG'), ('stop', 'JJ'), ('attack', 'NN'), ('united', 'JJ'), ('state', 'NN'), ('local', 'JJ'), ('police', 'NN'), ('know', 'VBD'), ('lot', 'NN'), ('people', 'NNS'), ('afraid', 'VBP'), ('anything', 'NN'), ('want', 'VBP'), ('accused', 'VBN'), ('profiling', 'VBG'), ('want', 'NN'), ('accused', 'VBD'), ('sort', 'JJ'), ('thing', 'NN'), ('trump', 'NN'), ('said', 'VBD'), ('fox', 'JJ'), ('friend', 'NN'), ('asked', 'VBD'), ('policy', 'NN'), ('would', 'MD'), ('implement', 'VB'), ('president', 'NN'), ('get', 'VB'), ('tough', 'JJ'), ('terrorism', 'NN'), ('argued', 'VBD'), ('country', 'NN'), ('choice', 'NN'), ('follow', 'VBP'), ('lead', 'NN'), ('israel', 'NN'), ('israel', 'NN'), ('done', 'VBN'), ('unbelievable', 'JJ'), ('job', 'NN'), ('profile', 'NN'), ('profile', 'NN'), ('see', 'VBP'), ('somebody', 'NN'), ('suspicious', 'JJ'), ('said', 'VBD'), ('profile', 'JJ'), ('take', 'VB'), ('person', 'NN'), ('check', 'NN'), ('choice', 'NN'), ('look', 'NN'), ('going', 'VBG'), ('really', 'RB'), ('choice', 'NN'), ('trying', 'VBG'), ('politically', 'RB'), ('correct', 'JJ'), ('country', 'NN'), ('going', 'VBG'), ('get', 'VB'), ('worse', 'JJR'), ('trump', 'NN'), ('previously', 'RB'), ('made', 'VBD'), ('similar', 'JJ'), ('comment', 'NN'), ('orlando', 'NN'), ('nightclub', 'IN'), ('shooting', 'VBG'), ('june', 'NN'), ('said', 'VBD'), ('interview', 'NN'), ('face', 'NN'), ('nation', 'NN'), ('something', 'NN'), ('needed', 'VBD'), ('seriously', 'RB'), ('consider', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "# you use the pos-tagger (it gives you back a list of tuples (word,pos))\n",
    "pos_sentence = nltk.pos_tag(lemma_sent)\n",
    "\n",
    "print (pos_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
